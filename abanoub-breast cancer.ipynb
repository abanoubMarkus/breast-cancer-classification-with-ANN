{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"breast cancer.ipynb","provenance":[],"authorship_tag":"ABX9TyPQZBc1BLwGxEE/fmtsyGB5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IUpuaqkOn7F8","colab_type":"text"},"source":["breast cancer\n"]},{"cell_type":"code","metadata":{"id":"pQRaQeLEn-it","colab_type":"code","colab":{}},"source":["import sys\n","import datetime\n","import numpy as np \n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import *\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_breast_cancer\n","plt.style.use('ggplot')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJAOskA57cbM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592844955759,"user_tz":-120,"elapsed":1151,"user":{"displayName":"bebo markus","photoUrl":"","userId":"04251859744417195579"}},"outputId":"7f8325f2-c71c-40a9-cf2a-9aef9ddf0d1c"},"source":["dataset = load_breast_cancer()\n","x = pd.DataFrame(dataset.data)\n","y = pd.DataFrame(dataset.target)\n","y.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(569, 1)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"TmNGxj8I9qCj","colab_type":"code","colab":{}},"source":["# Encoding categorical data\n","from sklearn.preprocessing import LabelEncoder\n","labelencoder_X_1 = LabelEncoder()\n","y = labelencoder_X_1.fit_transform(y)\n","\n","# Splitting the dataset into the Training set and Test set\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 0)\n","\n","#Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","x_train = sc.fit_transform(x_train)\n","x_test = sc.transform(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dg0_jAE48yeZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"executionInfo":{"status":"ok","timestamp":1592845308646,"user_tz":-120,"elapsed":1022,"user":{"displayName":"bebo markus","photoUrl":"","userId":"04251859744417195579"}},"outputId":"11677001-fae9-44c6-ffb5-b51b27101c0a"},"source":["# Regularization\n","l1_reg = keras.regularizers.l1(l=0.01)\n","RUN_NAME = \"_3L_5_10_\"\n","model = Sequential()\n","model.add(Dense(30, input_dim=30, activation='relu', name='input_layer'))\n","model.add(Dropout(0.2))\n","model.add(Dense(50, activation='relu', name='layer_1', kernel_regularizer=l1_reg))\n","model.add(Dropout(0.2))\n","model.add(Dense(1, activation='sigmoid', name='output_layer'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', \n","    metrics=['mae', 'acc'])\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_layer (Dense)          (None, 30)                930       \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 30)                0         \n","_________________________________________________________________\n","layer_1 (Dense)              (None, 50)                1550      \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 50)                0         \n","_________________________________________________________________\n","output_layer (Dense)         (None, 1)                 51        \n","=================================================================\n","Total params: 2,531\n","Trainable params: 2,531\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0T93P3sp-Eoq","colab_type":"code","colab":{}},"source":["# Create a TensorBoard logger\n","csv_logger = keras.callbacks.CSVLogger(\n","    'training_logs.csv', separator=',', append=False)\n","\n","checkpointer = keras.callbacks.ModelCheckpoint(filepath='models/sales.model.best.model.hdf5', \n","                               verbose=1, save_best_only=True, save_weights_only=False)\n","# filepath='/models/mnist.model.best.weights.{epoch:02d}-{val_loss:.2f}.hdf5\n","\n","log_dir = \"logs/fit/\" + RUN_NAME +datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","# Create EarlyStopping callback\n","early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0.001, patience=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x4VQt0a7-M2D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1592845324670,"user_tz":-120,"elapsed":11072,"user":{"displayName":"bebo markus","photoUrl":"","userId":"04251859744417195579"}},"outputId":"5935f051-ea3f-46c4-ccbc-f47577e08816"},"source":["hist = model.fit(\n","    x_train,\n","    y_train,\n","    validation_split=0.2,\n","    batch_size = 10,\n","    epochs=150,\n","    shuffle=True,\n","    verbose=2,\n","    callbacks=[csv_logger, tensorboard_callback , checkpointer, early_stopping]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/150\n","\n","Epoch 00001: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 2.3786 - mae: 0.3692 - acc: 0.7433 - val_loss: 2.0262 - val_mae: 0.2683 - val_acc: 0.9029\n","Epoch 2/150\n","\n","Epoch 00002: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 1.8166 - mae: 0.2235 - acc: 0.9218 - val_loss: 1.5640 - val_mae: 0.1657 - val_acc: 0.9515\n","Epoch 3/150\n","\n","Epoch 00003: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 1.4351 - mae: 0.1584 - acc: 0.9242 - val_loss: 1.2129 - val_mae: 0.1229 - val_acc: 0.9709\n","Epoch 4/150\n","\n","Epoch 00004: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 1.1059 - mae: 0.1292 - acc: 0.9511 - val_loss: 0.9276 - val_mae: 0.1053 - val_acc: 0.9903\n","Epoch 5/150\n","\n","Epoch 00005: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.8428 - mae: 0.1119 - acc: 0.9584 - val_loss: 0.6980 - val_mae: 0.0940 - val_acc: 0.9903\n","Epoch 6/150\n","\n","Epoch 00006: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.6556 - mae: 0.1090 - acc: 0.9633 - val_loss: 0.5240 - val_mae: 0.0859 - val_acc: 0.9903\n","Epoch 7/150\n","\n","Epoch 00007: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.5120 - mae: 0.1073 - acc: 0.9633 - val_loss: 0.4099 - val_mae: 0.0850 - val_acc: 0.9903\n","Epoch 8/150\n","\n","Epoch 00008: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.4030 - mae: 0.0963 - acc: 0.9731 - val_loss: 0.3284 - val_mae: 0.0781 - val_acc: 1.0000\n","Epoch 9/150\n","\n","Epoch 00009: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.3347 - mae: 0.0919 - acc: 0.9658 - val_loss: 0.2771 - val_mae: 0.0753 - val_acc: 1.0000\n","Epoch 10/150\n","\n","Epoch 00010: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.3044 - mae: 0.0966 - acc: 0.9658 - val_loss: 0.2450 - val_mae: 0.0750 - val_acc: 1.0000\n","Epoch 11/150\n","\n","Epoch 00011: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.2698 - mae: 0.0910 - acc: 0.9780 - val_loss: 0.2218 - val_mae: 0.0739 - val_acc: 1.0000\n","Epoch 12/150\n","\n","Epoch 00012: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.2516 - mae: 0.0881 - acc: 0.9682 - val_loss: 0.2034 - val_mae: 0.0699 - val_acc: 1.0000\n","Epoch 13/150\n","\n","Epoch 00013: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.2342 - mae: 0.0844 - acc: 0.9756 - val_loss: 0.1920 - val_mae: 0.0698 - val_acc: 1.0000\n","Epoch 14/150\n","\n","Epoch 00014: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.2235 - mae: 0.0861 - acc: 0.9658 - val_loss: 0.1787 - val_mae: 0.0654 - val_acc: 1.0000\n","Epoch 15/150\n","\n","Epoch 00015: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.2135 - mae: 0.0804 - acc: 0.9682 - val_loss: 0.1701 - val_mae: 0.0646 - val_acc: 1.0000\n","Epoch 16/150\n","\n","Epoch 00016: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1979 - mae: 0.0771 - acc: 0.9707 - val_loss: 0.1608 - val_mae: 0.0622 - val_acc: 1.0000\n","Epoch 17/150\n","\n","Epoch 00017: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1997 - mae: 0.0830 - acc: 0.9682 - val_loss: 0.1548 - val_mae: 0.0579 - val_acc: 1.0000\n","Epoch 18/150\n","\n","Epoch 00018: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1916 - mae: 0.0748 - acc: 0.9707 - val_loss: 0.1494 - val_mae: 0.0581 - val_acc: 1.0000\n","Epoch 19/150\n","\n","Epoch 00019: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1898 - mae: 0.0770 - acc: 0.9682 - val_loss: 0.1461 - val_mae: 0.0541 - val_acc: 1.0000\n","Epoch 20/150\n","\n","Epoch 00020: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1874 - mae: 0.0729 - acc: 0.9731 - val_loss: 0.1409 - val_mae: 0.0540 - val_acc: 1.0000\n","Epoch 21/150\n","\n","Epoch 00021: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1729 - mae: 0.0685 - acc: 0.9707 - val_loss: 0.1360 - val_mae: 0.0524 - val_acc: 1.0000\n","Epoch 22/150\n","\n","Epoch 00022: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1761 - mae: 0.0690 - acc: 0.9707 - val_loss: 0.1302 - val_mae: 0.0500 - val_acc: 1.0000\n","Epoch 23/150\n","\n","Epoch 00023: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1671 - mae: 0.0688 - acc: 0.9780 - val_loss: 0.1275 - val_mae: 0.0478 - val_acc: 1.0000\n","Epoch 24/150\n","\n","Epoch 00024: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1688 - mae: 0.0680 - acc: 0.9633 - val_loss: 0.1246 - val_mae: 0.0482 - val_acc: 1.0000\n","Epoch 25/150\n","\n","Epoch 00025: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1702 - mae: 0.0666 - acc: 0.9780 - val_loss: 0.1251 - val_mae: 0.0486 - val_acc: 0.9903\n","Epoch 26/150\n","\n","Epoch 00026: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1631 - mae: 0.0651 - acc: 0.9731 - val_loss: 0.1199 - val_mae: 0.0451 - val_acc: 1.0000\n","Epoch 27/150\n","\n","Epoch 00027: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1494 - mae: 0.0622 - acc: 0.9780 - val_loss: 0.1170 - val_mae: 0.0434 - val_acc: 1.0000\n","Epoch 28/150\n","\n","Epoch 00028: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1622 - mae: 0.0653 - acc: 0.9780 - val_loss: 0.1156 - val_mae: 0.0441 - val_acc: 1.0000\n","Epoch 29/150\n","\n","Epoch 00029: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1578 - mae: 0.0635 - acc: 0.9731 - val_loss: 0.1144 - val_mae: 0.0430 - val_acc: 1.0000\n","Epoch 30/150\n","\n","Epoch 00030: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1541 - mae: 0.0619 - acc: 0.9780 - val_loss: 0.1108 - val_mae: 0.0415 - val_acc: 1.0000\n","Epoch 31/150\n","\n","Epoch 00031: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1460 - mae: 0.0569 - acc: 0.9780 - val_loss: 0.1088 - val_mae: 0.0389 - val_acc: 1.0000\n","Epoch 32/150\n","\n","Epoch 00032: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1519 - mae: 0.0578 - acc: 0.9780 - val_loss: 0.1090 - val_mae: 0.0427 - val_acc: 1.0000\n","Epoch 33/150\n","\n","Epoch 00033: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1468 - mae: 0.0586 - acc: 0.9829 - val_loss: 0.1056 - val_mae: 0.0409 - val_acc: 1.0000\n","Epoch 34/150\n","\n","Epoch 00034: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1544 - mae: 0.0634 - acc: 0.9731 - val_loss: 0.1050 - val_mae: 0.0381 - val_acc: 1.0000\n","Epoch 35/150\n","\n","Epoch 00035: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1454 - mae: 0.0584 - acc: 0.9756 - val_loss: 0.1013 - val_mae: 0.0387 - val_acc: 1.0000\n","Epoch 36/150\n","\n","Epoch 00036: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1520 - mae: 0.0600 - acc: 0.9780 - val_loss: 0.1006 - val_mae: 0.0402 - val_acc: 1.0000\n","Epoch 37/150\n","\n","Epoch 00037: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1358 - mae: 0.0602 - acc: 0.9707 - val_loss: 0.0993 - val_mae: 0.0342 - val_acc: 1.0000\n","Epoch 38/150\n","\n","Epoch 00038: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1427 - mae: 0.0580 - acc: 0.9756 - val_loss: 0.0993 - val_mae: 0.0341 - val_acc: 1.0000\n","Epoch 39/150\n","\n","Epoch 00039: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1469 - mae: 0.0571 - acc: 0.9731 - val_loss: 0.0949 - val_mae: 0.0363 - val_acc: 1.0000\n","Epoch 40/150\n","\n","Epoch 00040: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1339 - mae: 0.0516 - acc: 0.9804 - val_loss: 0.0928 - val_mae: 0.0351 - val_acc: 1.0000\n","Epoch 41/150\n","\n","Epoch 00041: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1403 - mae: 0.0573 - acc: 0.9756 - val_loss: 0.0940 - val_mae: 0.0379 - val_acc: 1.0000\n","Epoch 42/150\n","\n","Epoch 00042: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1292 - mae: 0.0536 - acc: 0.9853 - val_loss: 0.0924 - val_mae: 0.0373 - val_acc: 1.0000\n","Epoch 43/150\n","\n","Epoch 00043: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1310 - mae: 0.0527 - acc: 0.9853 - val_loss: 0.0913 - val_mae: 0.0357 - val_acc: 1.0000\n","Epoch 44/150\n","\n","Epoch 00044: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1364 - mae: 0.0557 - acc: 0.9658 - val_loss: 0.0935 - val_mae: 0.0375 - val_acc: 1.0000\n","Epoch 45/150\n","\n","Epoch 00045: val_loss did not improve from 0.08874\n","41/41 - 0s - loss: 0.1370 - mae: 0.0574 - acc: 0.9780 - val_loss: 0.0894 - val_mae: 0.0346 - val_acc: 1.0000\n","Epoch 46/150\n","\n","Epoch 00046: val_loss improved from 0.08874 to 0.08732, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1324 - mae: 0.0545 - acc: 0.9804 - val_loss: 0.0873 - val_mae: 0.0320 - val_acc: 1.0000\n","Epoch 47/150\n","\n","Epoch 00047: val_loss did not improve from 0.08732\n","41/41 - 0s - loss: 0.1203 - mae: 0.0475 - acc: 0.9804 - val_loss: 0.0880 - val_mae: 0.0327 - val_acc: 0.9903\n","Epoch 48/150\n","\n","Epoch 00048: val_loss improved from 0.08732 to 0.08501, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1224 - mae: 0.0481 - acc: 0.9829 - val_loss: 0.0850 - val_mae: 0.0325 - val_acc: 1.0000\n","Epoch 49/150\n","\n","Epoch 00049: val_loss did not improve from 0.08501\n","41/41 - 0s - loss: 0.1362 - mae: 0.0542 - acc: 0.9731 - val_loss: 0.0922 - val_mae: 0.0324 - val_acc: 1.0000\n","Epoch 50/150\n","\n","Epoch 00050: val_loss did not improve from 0.08501\n","41/41 - 0s - loss: 0.1242 - mae: 0.0490 - acc: 0.9756 - val_loss: 0.0865 - val_mae: 0.0331 - val_acc: 1.0000\n","Epoch 51/150\n","\n","Epoch 00051: val_loss improved from 0.08501 to 0.08311, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1232 - mae: 0.0491 - acc: 0.9853 - val_loss: 0.0831 - val_mae: 0.0314 - val_acc: 1.0000\n","Epoch 52/150\n","\n","Epoch 00052: val_loss improved from 0.08311 to 0.08176, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1253 - mae: 0.0498 - acc: 0.9829 - val_loss: 0.0818 - val_mae: 0.0293 - val_acc: 1.0000\n","Epoch 53/150\n","\n","Epoch 00053: val_loss did not improve from 0.08176\n","41/41 - 0s - loss: 0.1274 - mae: 0.0478 - acc: 0.9756 - val_loss: 0.0864 - val_mae: 0.0346 - val_acc: 1.0000\n","Epoch 54/150\n","\n","Epoch 00054: val_loss did not improve from 0.08176\n","41/41 - 0s - loss: 0.1262 - mae: 0.0496 - acc: 0.9780 - val_loss: 0.0836 - val_mae: 0.0330 - val_acc: 1.0000\n","Epoch 55/150\n","\n","Epoch 00055: val_loss did not improve from 0.08176\n","41/41 - 0s - loss: 0.1192 - mae: 0.0485 - acc: 0.9780 - val_loss: 0.0826 - val_mae: 0.0328 - val_acc: 1.0000\n","Epoch 56/150\n","\n","Epoch 00056: val_loss improved from 0.08176 to 0.07994, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1175 - mae: 0.0498 - acc: 0.9829 - val_loss: 0.0799 - val_mae: 0.0279 - val_acc: 1.0000\n","Epoch 57/150\n","\n","Epoch 00057: val_loss did not improve from 0.07994\n","41/41 - 0s - loss: 0.1250 - mae: 0.0483 - acc: 0.9756 - val_loss: 0.0843 - val_mae: 0.0330 - val_acc: 1.0000\n","Epoch 58/150\n","\n","Epoch 00058: val_loss improved from 0.07994 to 0.07817, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1207 - mae: 0.0483 - acc: 0.9804 - val_loss: 0.0782 - val_mae: 0.0283 - val_acc: 1.0000\n","Epoch 59/150\n","\n","Epoch 00059: val_loss improved from 0.07817 to 0.07700, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1199 - mae: 0.0479 - acc: 0.9853 - val_loss: 0.0770 - val_mae: 0.0285 - val_acc: 1.0000\n","Epoch 60/150\n","\n","Epoch 00060: val_loss did not improve from 0.07700\n","41/41 - 0s - loss: 0.1230 - mae: 0.0475 - acc: 0.9853 - val_loss: 0.0779 - val_mae: 0.0305 - val_acc: 1.0000\n","Epoch 61/150\n","\n","Epoch 00061: val_loss improved from 0.07700 to 0.07491, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1184 - mae: 0.0506 - acc: 0.9756 - val_loss: 0.0749 - val_mae: 0.0271 - val_acc: 1.0000\n","Epoch 62/150\n","\n","Epoch 00062: val_loss did not improve from 0.07491\n","41/41 - 0s - loss: 0.1218 - mae: 0.0465 - acc: 0.9780 - val_loss: 0.0786 - val_mae: 0.0308 - val_acc: 1.0000\n","Epoch 63/150\n","\n","Epoch 00063: val_loss did not improve from 0.07491\n","41/41 - 0s - loss: 0.1226 - mae: 0.0502 - acc: 0.9780 - val_loss: 0.0757 - val_mae: 0.0268 - val_acc: 1.0000\n","Epoch 64/150\n","\n","Epoch 00064: val_loss did not improve from 0.07491\n","41/41 - 0s - loss: 0.1183 - mae: 0.0472 - acc: 0.9804 - val_loss: 0.0762 - val_mae: 0.0259 - val_acc: 1.0000\n","Epoch 65/150\n","\n","Epoch 00065: val_loss improved from 0.07491 to 0.07397, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1130 - mae: 0.0430 - acc: 0.9878 - val_loss: 0.0740 - val_mae: 0.0279 - val_acc: 1.0000\n","Epoch 66/150\n","\n","Epoch 00066: val_loss improved from 0.07397 to 0.07358, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1169 - mae: 0.0476 - acc: 0.9756 - val_loss: 0.0736 - val_mae: 0.0258 - val_acc: 1.0000\n","Epoch 67/150\n","\n","Epoch 00067: val_loss did not improve from 0.07358\n","41/41 - 0s - loss: 0.1155 - mae: 0.0470 - acc: 0.9780 - val_loss: 0.0774 - val_mae: 0.0289 - val_acc: 1.0000\n","Epoch 68/150\n","\n","Epoch 00068: val_loss did not improve from 0.07358\n","41/41 - 0s - loss: 0.1109 - mae: 0.0442 - acc: 0.9829 - val_loss: 0.0803 - val_mae: 0.0304 - val_acc: 1.0000\n","Epoch 69/150\n","\n","Epoch 00069: val_loss did not improve from 0.07358\n","41/41 - 0s - loss: 0.1224 - mae: 0.0463 - acc: 0.9780 - val_loss: 0.0806 - val_mae: 0.0315 - val_acc: 0.9903\n","Epoch 70/150\n","\n","Epoch 00070: val_loss improved from 0.07358 to 0.07107, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1053 - mae: 0.0394 - acc: 0.9829 - val_loss: 0.0711 - val_mae: 0.0245 - val_acc: 1.0000\n","Epoch 71/150\n","\n","Epoch 00071: val_loss did not improve from 0.07107\n","41/41 - 0s - loss: 0.1139 - mae: 0.0417 - acc: 0.9853 - val_loss: 0.0716 - val_mae: 0.0269 - val_acc: 1.0000\n","Epoch 72/150\n","\n","Epoch 00072: val_loss did not improve from 0.07107\n","41/41 - 0s - loss: 0.1040 - mae: 0.0422 - acc: 0.9853 - val_loss: 0.0730 - val_mae: 0.0288 - val_acc: 1.0000\n","Epoch 73/150\n","\n","Epoch 00073: val_loss did not improve from 0.07107\n","41/41 - 0s - loss: 0.1064 - mae: 0.0437 - acc: 0.9804 - val_loss: 0.0713 - val_mae: 0.0282 - val_acc: 1.0000\n","Epoch 74/150\n","\n","Epoch 00074: val_loss improved from 0.07107 to 0.07005, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1090 - mae: 0.0469 - acc: 0.9756 - val_loss: 0.0700 - val_mae: 0.0255 - val_acc: 1.0000\n","Epoch 75/150\n","\n","Epoch 00075: val_loss did not improve from 0.07005\n","41/41 - 0s - loss: 0.1159 - mae: 0.0459 - acc: 0.9780 - val_loss: 0.0710 - val_mae: 0.0256 - val_acc: 1.0000\n","Epoch 76/150\n","\n","Epoch 00076: val_loss improved from 0.07005 to 0.06837, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1068 - mae: 0.0432 - acc: 0.9829 - val_loss: 0.0684 - val_mae: 0.0254 - val_acc: 1.0000\n","Epoch 77/150\n","\n","Epoch 00077: val_loss improved from 0.06837 to 0.06763, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1039 - mae: 0.0404 - acc: 0.9853 - val_loss: 0.0676 - val_mae: 0.0234 - val_acc: 1.0000\n","Epoch 78/150\n","\n","Epoch 00078: val_loss did not improve from 0.06763\n","41/41 - 0s - loss: 0.1072 - mae: 0.0434 - acc: 0.9804 - val_loss: 0.0687 - val_mae: 0.0263 - val_acc: 1.0000\n","Epoch 79/150\n","\n","Epoch 00079: val_loss improved from 0.06763 to 0.06646, saving model to models/sales.model.best.model.hdf5\n","41/41 - 0s - loss: 0.1094 - mae: 0.0463 - acc: 0.9829 - val_loss: 0.0665 - val_mae: 0.0231 - val_acc: 1.0000\n","Epoch 80/150\n","\n","Epoch 00080: val_loss did not improve from 0.06646\n","41/41 - 0s - loss: 0.1194 - mae: 0.0466 - acc: 0.9756 - val_loss: 0.0690 - val_mae: 0.0240 - val_acc: 1.0000\n","Epoch 81/150\n","\n","Epoch 00081: val_loss did not improve from 0.06646\n","41/41 - 0s - loss: 0.1137 - mae: 0.0474 - acc: 0.9756 - val_loss: 0.0710 - val_mae: 0.0220 - val_acc: 1.0000\n","Epoch 82/150\n","\n","Epoch 00082: val_loss did not improve from 0.06646\n","41/41 - 0s - loss: 0.1016 - mae: 0.0376 - acc: 0.9804 - val_loss: 0.0670 - val_mae: 0.0252 - val_acc: 1.0000\n","Epoch 83/150\n","\n","Epoch 00083: val_loss did not improve from 0.06646\n","41/41 - 0s - loss: 0.1135 - mae: 0.0427 - acc: 0.9829 - val_loss: 0.0772 - val_mae: 0.0291 - val_acc: 1.0000\n","Epoch 84/150\n","\n","Epoch 00084: val_loss did not improve from 0.06646\n","41/41 - 0s - loss: 0.1117 - mae: 0.0462 - acc: 0.9780 - val_loss: 0.0680 - val_mae: 0.0248 - val_acc: 1.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"URNrEz3i-2ZE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":821},"executionInfo":{"status":"ok","timestamp":1592845378536,"user_tz":-120,"elapsed":4358,"user":{"displayName":"bebo markus","photoUrl":"","userId":"04251859744417195579"}},"outputId":"81e2dd68-e53b-438a-9203-e61f98a45ef3"},"source":["%load_ext tensorboard\n","%tensorboard --logdir logs/fit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"laxtKrdJBK7k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1592845976337,"user_tz":-120,"elapsed":1027,"user":{"displayName":"bebo markus","photoUrl":"","userId":"04251859744417195579"}},"outputId":"d05de96f-1329-4191-bbd8-365697ea16f0"},"source":["from sklearn.metrics import confusion_matrix\n","y_pred = model.predict_classes(X_test)\n","cm = confusion_matrix(y_test, y_pred)\n","print('confusion matrix is :',cm )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-20-3ccf241bf892>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n","Instructions for updating:\n","Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","confusion matrix is : [[22  0]\n"," [ 0 35]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8UAOzCKtBMP2","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}